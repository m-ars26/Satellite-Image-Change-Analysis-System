"""
ğŸ›°ï¸ Uydu GÃ¶rÃ¼ntÃ¼ Ã–n Ä°ÅŸleme ModÃ¼lÃ¼
Uydu gÃ¶rÃ¼ntÃ¼leriyle Ã§alÄ±ÅŸÄ±rken ilk adÄ±mda yaptÄ±ÄŸÄ±m iÅŸlemleri iÃ§eren modÃ¼l. 
BoyutlandÄ±rma, gÃ¼rÃ¼ltÃ¼ temizleme, kontrast artÄ±rÄ±mÄ± ve hizalama gibi temel Ã¶n iÅŸlemleri burada tanÄ±mladÄ±m.
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from typing import Tuple, Optional, Dict, Any
import logging

# Loglama ayarlarÄ±nÄ± baÅŸtan yapÄ±yorum ki hata veya bilgi Ã§Ä±ktÄ±larÄ± terminale dÃ¼zgÃ¼n dÃ¼ÅŸsÃ¼n.
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ImagePreprocessor:
    """
    Uydu gÃ¶rÃ¼ntÃ¼lerini iÅŸlerken kullandÄ±ÄŸÄ±m Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± ve hizalama algoritmalarÄ±nÄ± iÃ§eren sÄ±nÄ±f.
    Ã–zellikle boyutlandÄ±rma, gÃ¼rÃ¼ltÃ¼ azaltma, kontrast iyileÅŸtirme ve hizalama gibi iÅŸlemleri kapsÄ±yor.
    """

    def __init__(self, target_size: Tuple[int, int] = (1024, 1024)):
        """
        BaÅŸlangÄ±Ã§ta hedef boyutu belirtiyorum. Bu boyuta gÃ¶re gÃ¶rseller normalize ediliyor.
        CUDA destekliyse GPUâ€™da Ã§alÄ±ÅŸacak ÅŸekilde ayarlanÄ±yor.
        """
        self.target_size = target_size
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ImagePreprocessor baÅŸlatÄ±ldÄ±. Device: {self.device}")
    
    def load_and_preprocess(self, image_path: str) -> np.ndarray:
        """
        Verilen gÃ¶rsel yolundan resmi okuyup tÃ¼m Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± sÄ±rasÄ±yla uyguluyor.
        GÃ¶rÃ¼ntÃ¼ yoksa hata fÄ±rlatÄ±yor.
        """
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {image_path}")
        
        logger.info(f"GÃ¶rÃ¼ntÃ¼ yÃ¼klendi: {image_path}, boyut: {image.shape}")
        return self._preprocess_pipeline(image)

    def _preprocess_pipeline(self, image: np.ndarray) -> np.ndarray:
        """
        BÃ¼tÃ¼n Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± sÄ±rayla uyguladÄ±ÄŸÄ±m fonksiyon. 
        SÄ±rasÄ±yla: yeniden boyutlandÄ±rma, gÃ¼rÃ¼ltÃ¼ azaltma, kontrast artÄ±rma, histogram eÅŸitleme ve normalize etme.
        """
        resized = self._resize_image(image)
        denoised = self._denoise_image(resized)
        enhanced = self._enhance_contrast(denoised)
        equalized = self._histogram_equalization(enhanced)
        normalized = self._normalize_image(equalized)
        return normalized
    
    def _resize_image(self, image: np.ndarray) -> np.ndarray:
        """GÃ¶rseli hedef boyuta gÃ¶re yeniden boyutlandÄ±rÄ±yorum."""
        return cv2.resize(image, self.target_size, interpolation=cv2.INTER_LANCZOS4)
    
    def _denoise_image(self, image: np.ndarray) -> np.ndarray:
        """Renkli gÃ¶rÃ¼ntÃ¼deki gÃ¼rÃ¼ltÃ¼yÃ¼ azaltmak iÃ§in Non-Local Means filtresi kullanÄ±yorum."""
        return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)
    
    def _enhance_contrast(self, image: np.ndarray) -> np.ndarray:
        """
        KontrastÄ± artÄ±rmak iÃ§in CLAHE (Adaptive Histogram Equalization) yÃ¶ntemini sadece L (parlaklÄ±k) kanalÄ±na uyguluyorum.
        """
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        merged = cv2.merge([l, a, b])
        return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)
    
    def _histogram_equalization(self, image: np.ndarray) -> np.ndarray:
        """
        BGR kanallarÄ±nÄ± tek tek eÅŸitleyerek daha homojen bir kontrast daÄŸÄ±lÄ±mÄ± saÄŸlamaya Ã§alÄ±ÅŸÄ±yorum.
        """
        channels = cv2.split(image)
        eq_channels = [cv2.equalizeHist(c) for c in channels]
        return cv2.merge(eq_channels)
    
    def _normalize_image(self, image: np.ndarray) -> np.ndarray:
        """Son olarak tÃ¼m piksel deÄŸerlerini 0-255 aralÄ±ÄŸÄ±na Ã§ekip uint8 formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yorum."""
        return cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    def align_images(self, image1: np.ndarray, image2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Ä°ki gÃ¶rseli hizalamak iÃ§in Ã¶nce ORB (feature tabanlÄ±), baÅŸarÄ±sÄ±z olursa ECC (yoÄŸunluk tabanlÄ±) yÃ¶ntemini kullanÄ±yorum.
        """
        logger.info("GÃ¶rÃ¼ntÃ¼ hizalama baÅŸlatÄ±ldÄ±...")
        aligned = self._orb_alignment(image1, image2)
        if aligned is None:
            logger.warning("ORB baÅŸarÄ±sÄ±z oldu, ECC denenecek.")
            aligned = self._ecc_alignment(image1, image2)
        
        if aligned is None:
            logger.warning("Hizalama baÅŸarÄ±sÄ±z oldu. GÃ¶rseller orijinal halleriyle dÃ¶necek.")
            return image1, image2
        
        logger.info("Hizalama baÅŸarÄ±lÄ±.")
        return image1, aligned
    
    def _orb_alignment(self, img1: np.ndarray, img2: np.ndarray) -> Optional[np.ndarray]:
        """
        ORB algoritmasÄ±yla anahtar nokta eÅŸlemesi yapÄ±p homografi matrisi ile hizalama denemesi yapÄ±yorum.
        """
        try:
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            orb = cv2.ORB_create(nfeatures=1000)
            kp1, des1 = orb.detectAndCompute(gray1, None)
            kp2, des2 = orb.detectAndCompute(gray2, None)
            if des1 is None or des2 is None:
                return None
            matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
            matches = sorted(matcher.match(des1, des2), key=lambda x: x.distance)
            good = matches[:int(len(matches) * 0.15)]
            if len(good) < 4:
                return None
            src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)
            matrix, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)
            if matrix is None:
                return None
            h, w = img1.shape[:2]
            return cv2.warpPerspective(img2, matrix, (w, h))
        except Exception as e:
            logger.error(f"ORB hizalama hatasÄ±: {e}")
            return None
    
    def _ecc_alignment(self, img1: np.ndarray, img2: np.ndarray) -> Optional[np.ndarray]:
        """
        EÄŸer ORB baÅŸarÄ±sÄ±z olursa, bu yedek yÃ¶ntem olarak ECC (intensity tabanlÄ± hizalama) kullanÄ±yorum.
        Ã–zellikle yapÄ±lar fazla deÄŸiÅŸmemiÅŸse daha baÅŸarÄ±lÄ± sonuÃ§lar verebiliyor.
        """
        try:
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.float32)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.float32)
            warp = np.eye(2, 3, dtype=np.float32)
            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 50, 1e-10)
            try:
                _, warp = cv2.findTransformECC(gray1, gray2, warp, cv2.MOTION_AFFINE, criteria)
                h, w = img1.shape[:2]
                return cv2.warpAffine(img2, warp, (w, h))
            except cv2.error:
                return None
        except Exception as e:
            logger.error(f"ECC hizalama hatasÄ±: {e}")
            return None
    
    def calculate_alignment_quality(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """
        Ä°ki gÃ¶rÃ¼ntÃ¼nÃ¼n ne kadar Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§mek iÃ§in normalize edilmiÅŸ korelasyon katsayÄ±sÄ± hesaplÄ±yorum.
        DeÄŸeri 0 ile 1 arasÄ±nda Ã§Ä±kÄ±yor.
        """
        g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.float32)
        g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.float32)
        g1 = (g1 - np.mean(g1)) / np.std(g1)
        g2 = (g2 - np.mean(g2)) / np.std(g2)
        corr = np.corrcoef(g1.flatten(), g2.flatten())[0, 1]
        return max(0, corr)
    
    def get_preprocessing_stats(self, original: np.ndarray, processed: np.ndarray) -> Dict[str, Any]:
        """
        GÃ¶rsellerin iÅŸlem Ã¶ncesi ve sonrasÄ± bazÄ± istatistiklerini (ortalama, std, boyut, kontrast farkÄ±) kÄ±yaslamak iÃ§in hesaplÄ±yorum.
        """
        return {
            'original_shape': original.shape,
            'processed_shape': processed.shape,
            'original_mean': np.mean(original),
            'processed_mean': np.mean(processed),
            'original_std': np.std(original),
            'processed_std': np.std(processed),
            'contrast_improvement': np.std(processed) / np.std(original) if np.std(original) > 0 else 1.0
        }

def test_preprocessor():
    """
    Preprocessing aÅŸamasÄ±nÄ± test ettiÄŸim, gÃ¶rselleri iÅŸleyip karÅŸÄ±laÅŸtÄ±rmalÄ± bir Ã§Ä±ktÄ± Ã¼reten basit bir test fonksiyonu.
    SonuÃ§lar hem ekrana yazÄ±lÄ±yor hem de PNG olarak kaydediliyor.
    """
    import matplotlib.pyplot as plt
    print("ğŸ§ª Preprocessor testi baÅŸlatÄ±ldÄ±.")
    
    test_paths = [
        "data/before/test_image.jpg",
        "data/after/test_image.jpg"
    ]
    
    for path in test_paths:
        if not cv2.imread(path) is not None:
            print(f"âŒ Test gÃ¶rseli bulunamadÄ±: {path}")
            return
    
    preprocessor = ImagePreprocessor(target_size=(400, 400))
    
    img1_original = cv2.imread(test_paths[0])
    img2_original = cv2.imread(test_paths[1])
    
    print("ğŸ”„ Ã–n iÅŸleme uygulanÄ±yor...")
    img1_processed = preprocessor._preprocess_pipeline(img1_original)
    img2_processed = preprocessor._preprocess_pipeline(img2_original)
    
    print("ğŸ”„ GÃ¶rseller hizalanÄ±yor...")
    img1_aligned, img2_aligned = preprocessor.align_images(img1_processed, img2_processed)
    
    quality = preprocessor.calculate_alignment_quality(img1_aligned, img2_aligned)
    print(f"ğŸ“Š Hizalama skoru: {quality:.3f}")
    
    stats1 = preprocessor.get_preprocessing_stats(img1_original, img1_processed)
    stats2 = preprocessor.get_preprocessing_stats(img2_original, img2_processed)
    
    print("ğŸ“ˆ Ä°statistikler:")
    print(f"GÃ¶rsel 1 - Kontrast iyileÅŸmesi: {stats1['contrast_improvement']:.2f}x")
    print(f"GÃ¶rsel 2 - Kontrast iyileÅŸmesi: {stats2['contrast_improvement']:.2f}x")
    
    # GÃ¶rsel sonuÃ§larÄ± Ã§izip kaydediyorum
    plt.figure(figsize=(16, 8))
    plt.subplot(2, 4, 1)
    plt.imshow(cv2.cvtColor(img1_original, cv2.COLOR_BGR2RGB))
    plt.title("Before - Original")
    plt.axis('off')

    plt.subplot(2, 4, 2)
    plt.imshow(cv2.cvtColor(img2_original, cv2.COLOR_BGR2RGB))
    plt.title("After - Original")
    plt.axis('off')

    plt.subplot(2, 4, 3)
    plt.imshow(cv2.cvtColor(img1_processed, cv2.COLOR_BGR2RGB))
    plt.title("Before - Processed")
    plt.axis('off')

    plt.subplot(2, 4, 4)
    plt.imshow(cv2.cvtColor(img2_processed, cv2.COLOR_BGR2RGB))
    plt.title("After - Processed")
    plt.axis('off')

    plt.subplot(2, 4, 5)
    plt.imshow(cv2.cvtColor(img1_aligned, cv2.COLOR_BGR2RGB))
    plt.title("Before - Aligned")
    plt.axis('off')

    plt.subplot(2, 4, 6)
    plt.imshow(cv2.cvtColor(img2_aligned, cv2.COLOR_BGR2RGB))
    plt.title("After - Aligned")
    plt.axis('off')

    diff = cv2.absdiff(img1_aligned, img2_aligned)
    plt.subplot(2, 4, 7)
    plt.imshow(cv2.cvtColor(diff, cv2.COLOR_BGR2RGB))
    plt.title("Difference")
    plt.axis('off')

    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    plt.subplot(2, 4, 8)
    plt.hist(diff_gray.flatten(), bins=50, alpha=0.7)
    plt.title("Difference Histogram")
    plt.xlabel("Intensity")
    plt.ylabel("Frequency")
    
    plt.tight_layout()
    plt.savefig("results/preprocessing_test.png", dpi=150, bbox_inches='tight')
    plt.show()
    
    print("âœ… Test tamamlandÄ±. SonuÃ§: results/preprocessing_test.png")

if __name__ == "__main__":
    test_preprocessor()
